---
layout: page_full
title: Tutorial 
background: '/img/bg-index.jpg'
---
<p><span style="font-size: 28pt; font-family: 'Arial', Helvetica, sans-serif;"><em>Tutorial (IEEE CEC 2022)</em></span></p>
<p><span style="font-size: 24pt; font-family: 'Arial', Helvetica, sans-serif;">How to Compare Evolutionary Multi-Objective Optimization Algorithms: Parameter Specifications, Indicators and Test Problems </span>
<br><span style="font-size: 18pt; font-family: 'Arial', Helvetica, sans-serif;"><em>The IEEE World Congress on Computational Intelligence 2022 </em></span>
<br><span style="font-size: 18pt; font-family: 'Arial', Helvetica, sans-serif;"><em>18-23 July, 2022, Padua, Italy </em></span><br></p>

<p><span style="font-size: 20pt; font-family: 'Arial', Helvetica, sans-serif;"><b>Topic introduction: </b></span><br>  
<span style="font-size: 16pt; font-family: 'Arial', Helvetica, sans-serif;">Evolutionary multi-objective optimization (EMO) has been a very active research area in recent years. Almost every year, new EMO algorithms are proposed. When a new EMO algorithm is proposed, computational experiments are usually conducted in order to compare its performance with existing algorithms. 
Then, experimental results are summarized and reported as a number of tables together with statistical significance test results. Those results usually show higher performance of the new algorithm than existing algorithms. However, fair comparison of different EMO algorithms is not easy since the evaluated performance of each algorithm usually depends on experimental settings. 
This is also because solution sets instead of solutions are evaluated.</span></p>

<p><span style="font-size: 16pt; font-family: 'Arial', Helvetica, sans-serif;">In this tutorial, we will first explain some commonly-used software platforms and experimental settings for the comparison of EMO algorithms. Then, we will discuss how to specify the common setting of computational experiments, which is used by all the compared EMO algorithms. 
  More specifically, the focus of this tutorial is the setting related to the following four issues: (i) termination condition, (ii) population size, (iii) performance indicators, (iv) test problem. 
  For each issue, we will provide a clear demonstration of its strong effects on comparison results of EMO algorithms. Following that, we will discuss how to handle each of these issues for fair comparison. 
  These discussions aim to encourage the future development of the EMO research field without focusing too much on the development of overly-specialized new algorithms in a specific setting. 
  Finally, we will also suggest some promising future research topics related to each issue.</span></p>


<p><span style="font-size: 20pt; font-family: 'Arial', Helvetica, sans-serif;"><b>Outline of the tutorial: </b></span><br>
<span style="font-size: 16pt; font-family: 'Arial', Helvetica, sans-serif;">The duration of the tutorial will be 1.5 hours. It will be composed of the following parts:<br>
1.	Brief introduction to multi-objective optimization<br>
2.	Explanations on some commonly-used software platforms and experimental settings for the comparison of EMO algorithms<br>
3.	The difficulties in fair performance comparison of EMO algorithms related to the following four issues and how to handle them:<br>
<ul> 
  <li>Termination condition</li>
  <li>Population size </li>
  <li>Performance indicators</li> 
  <li>Test problem </li>
 </ul>
<br>4.	Future research topics related to each issue </span>
