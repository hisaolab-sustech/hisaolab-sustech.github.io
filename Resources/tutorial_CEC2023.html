---
layout: page_full
title: Tutorials 
background: '/img/bg-index.jpg'
---
<p><span style="color:red;font-size: 18pt;"><em><b> Tutorial (IEEE CEC 2023) <a href ="https://2023.ieee-cec.org/tutorials/"> [Link] </a></b></em></span></p>  
<p><span style="font-size: 24pt; font-family: 'Arial', Helvetica, sans-serif;">How to Compare Evolutionary Multi-Objective Optimization Algorithms: Parameter Specifications, Indicators and Test Problems </span>
<br><span style="font-size: 18pt; font-family: 'Arial', Helvetica, sans-serif;"><em>IEEE 2023 Congress on Evolutionary Computation (CEC)</em></span>
<br><span style="font-size: 18pt; font-family: 'Arial', Helvetica, sans-serif;"><em>1-5 July, 2023, Chicago, USA </em></span><br></p>

<p><span style="font-size: 20pt; font-family: 'Arial', Helvetica, sans-serif;"><b>Topic introduction: </b></span><br>  
<span style="font-size: 16pt; font-family: 'Arial', Helvetica, sans-serif;">Evolutionary multi-objective optimization (EMO) has been a very active research area in recent years. Almost every year, new EMO algorithms are proposed. When a new EMO algorithm is proposed, computational experiments are usually conducted in order to compare its performance with existing algorithms. 
Then, experimental results are summarized and reported as a number of tables together with statistical significance test results. Those results usually show higher performance of the new algorithm than existing algorithms. However, fair comparison of different EMO algorithms is not easy since the evaluated performance of each algorithm usually depends on experimental settings. 
This is also because solution sets instead of solutions are evaluated.</span></p>

<p><span style="font-size: 16pt; font-family: 'Arial', Helvetica, sans-serif;">In this tutorial, we will first explain some commonly-used software platforms and experimental settings for the comparison of EMO algorithms. Then, we will discuss how to specify the common setting of computational experiments, which is used by all the compared EMO algorithms. 
  More specifically, the focus of this tutorial is the setting related to the following four issues: (i) termination condition, (ii) population size, (iii) performance indicators, (iv) test problem. 
  For each issue, we will provide a clear demonstration of its strong effects on comparison results of EMO algorithms. Following that, we will discuss how to handle each of these issues for fair comparison. 
  These discussions aim to encourage the future development of the EMO research field without focusing too much on the development of overly-specialized new algorithms in a specific setting. 
  Finally, we will also suggest some promising future research topics related to each issue.</span></p>


<p><span style="font-size: 20pt; font-family: 'Arial', Helvetica, sans-serif;"><b>Outline of the tutorial: </b></span><br>
<span style="font-size: 16pt; font-family: 'Arial', Helvetica, sans-serif;">The duration of the tutorial will be two hours. It will be composed of the following parts:<br>
1.	Brief introduction to multi-objective optimization<br>
2.	Explanations on some commonly-used software platforms and experimental settings for the comparison of EMO algorithms<br>
3.	The difficulties in fair performance comparison of EMO algorithms related to the following four issues and how to handle them:<br>
&nbsp&nbsp&nbsp&nbsp- Termination condition<br>
&nbsp&nbsp&nbsp&nbsp- Population size <br>
&nbsp&nbsp&nbsp&nbsp- Performance indicators<br>
&nbsp&nbsp&nbsp&nbsp- Test problem <br>
4.	Future research topics related to each issue </span></p>

 <p><span style="font-size: 20pt; font-family: 'Arial', Helvetica, sans-serif;"><b>Speakers: </b></span><br>
 <p><span style="font-size: 16pt; font-family: 'Arial', Helvetica, sans-serif;"><b>Lie Meng Pang, Southern University of Science and Technology, China.</b><br>
   Lie Meng Pang received her Bachelor of Engineering degree in Electronic and Telecommunication Engineering and Ph.D. degree in Electronic Engineering from the Faculty of Engineering, Universiti Malaysia Sarawak, Malaysia, in 2012 and 2018, respectively. 
   She is currently a research associate with the Department of Computer Science and Engineering, Southern University of Science and Technology (SUSTech), China. 
   Her current research interests include evolutionary multi-objective optimization and fuzzy systems.</p>
 
 <p><span style="font-size: 16pt; font-family: 'Arial', Helvetica, sans-serif;"><b>Ke Shang, Southern University of Science and Technology, China.</b><br>
   Ke Shang received the B.S. and Ph.D. degrees from Xiâ€™an Jiaotong University, China, in 2009 and 2016, respectively. 
   He is currently a research assistant professor at Southern University of Science and Technology, China. 
   His current research interests include evolutionary multi-objective optimization and its applications. 
   He received GECCO 2018 Best Paper Award, CEC 2019 First Runner-up Conference Paper Award, GECCO 2021 Best Paper Award and best paper nomination at PPSN 2020. </p>

 <span style="font-size: 16pt; font-family: 'Arial', Helvetica, sans-serif;"><b>Hisao Ishibuchi, Southern University of Science and Technology, China.</b><br>
  Hisao Ishibuchi is a Chair Professor at Southern University of Science and Technology, China. 
   He was the IEEE Computational Intelligence Society (CIS) Vice-President for Technical Activities in 2010-2013 and the Editor-in-Chief of the IEEE Computational Intelligence Magazine in 2014-2019. 
   Currently he is an IEEE CIS Administrative Committee Member (2014-2019, 2021-2023), an IEEE CIS Distinguished Lecturer (2015-2017, 2021-2023), and an Associate Editor of several journals such as IEEE Trans. on Evolutionary Computation, IEEE Trans. on Cybernetics, and IEEE Access. 
   He is also General Chair of IEEE WCCI 2024. His research on evolutionary multi-objective optimization received an Outstanding Paper Award from IEEE Trans. on Evolutionary Computation in 2020, and Best Paper Awards from GECCO 2004, 2017, 2018, 2020, 2021 and EMO 2019.</p>
